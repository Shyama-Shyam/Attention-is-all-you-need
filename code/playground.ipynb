{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_tokenizer import *\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_raw = load_dataset(\"cfilt/iitb-english-hindi\", split= 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_src = get_or_build_tokenizer(config, ds_raw, config['lang_src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_tgt = Tokenizer.from_file(\"tokenizer_hi.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentence: 2176\n",
      "Max length of target sentence: 2068\n"
     ]
    }
   ],
   "source": [
    "max_len_src = 0\n",
    "max_len_tgt = 0\n",
    "for item in ds_raw:\n",
    "        src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n",
    "        tgt_ids = tokenizer_tgt.encode(item['translation'][config['lang_tgt']]).ids\n",
    "        max_len_src = max(max_len_src, len(src_ids))\n",
    "        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
    "\n",
    "print(f'Max length of source sentence: {max_len_src}')\n",
    "print(f'Max length of target sentence: {max_len_tgt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['translation'],\n",
      "    num_rows: 1659083\n",
      "})\n",
      "{'translation': {'en': 'Give your application an accessibility workout', 'hi': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'}}\n"
     ]
    }
   ],
   "source": [
    "print(ds_raw)\n",
    "print(ds_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Initialize an empty list to store filtered rows\n",
    "truncated_rows = []\n",
    "\n",
    "# Define the maximum length threshold\n",
    "max_length_threshold = 340\n",
    "\n",
    "# Iterate through ds_raw and filter rows\n",
    "for item in ds_raw:\n",
    "    src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n",
    "    tgt_ids = tokenizer_tgt.encode(item['translation'][config['lang_tgt']]).ids\n",
    "    \n",
    "    # Check if the length of source and target sentences is less than the threshold\n",
    "    if len(src_ids) <= max_length_threshold and len(tgt_ids) <= max_length_threshold:\n",
    "        # Add the row to truncated_rows\n",
    "        truncated_rows.append(item)\n",
    "\n",
    "# Create a new dataset ds_truncated containing the filtered rows\n",
    "ds_truncated = Dataset.from_dict({\"translation\": [item[\"translation\"] for item in truncated_rows]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['translation'],\n",
      "    num_rows: 1658990\n",
      "})\n",
      "{'translation': {'en': 'Give your application an accessibility workout', 'hi': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'}}\n"
     ]
    }
   ],
   "source": [
    "print(ds_truncated)\n",
    "print(ds_truncated[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentence: 335\n",
      "Max length of target sentence: 333\n"
     ]
    }
   ],
   "source": [
    "max_len_src = 0\n",
    "max_len_tgt = 0\n",
    "for item in ds_truncated:\n",
    "        src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n",
    "        tgt_ids = tokenizer_tgt.encode(item['translation'][config['lang_tgt']]).ids\n",
    "        max_len_src = max(max_len_src, len(src_ids))\n",
    "        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
    "\n",
    "print(f'Max length of source sentence: {max_len_src}')\n",
    "print(f'Max length of target sentence: {max_len_tgt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1658990/1658990 [00:00<00:00, 1836628.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds_truncated.save_to_disk(\"ds_truncated.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_raw = load_dataset(\"adilgupta/cfilt-iitb-en-hi-truncated\", split= 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['translation'],\n",
      "    num_rows: 1658990\n",
      "})\n",
      "{'translation': {'en': 'Give your application an accessibility workout', 'hi': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'}}\n"
     ]
    }
   ],
   "source": [
    "print(ds_truncated)\n",
    "print(ds_truncated[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Certificate Authority Trust', 'hi': 'प्रमाणपत्र प्राधिकार ट्रस्ट'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_truncated[98789]['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation'],\n",
       "    num_rows: 1658990\n",
       "})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1659/1659 [00:03<00:00, 528.42ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:30<00:00, 30.55s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/adilgupta/cfilt-iitb-en-hi-truncated/commit/2c708567441fa8cf8cf905709c69cbde85323b1c', commit_message='Upload dataset', commit_description='', oid='2c708567441fa8cf8cf905709c69cbde85323b1c', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_truncated.push_to_hub(\"cfilt-iitb-en-hi-truncated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 354/354 [00:00<?, ?B/s] \n",
      "Downloading data: 100%|██████████| 199M/199M [00:28<00:00, 6.95MB/s] \n",
      "Generating train split: 100%|██████████| 1658990/1658990 [00:05<00:00, 284943.27 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds_raw = load_dataset(\"adilgupta/cfilt-iitb-en-hi-truncated\", split= 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation'],\n",
       "    num_rows: 1658990\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
